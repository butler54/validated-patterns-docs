:_content-type: PROCEDURE
:imagesdir: ../../../images

[id="creating-data-science-project"]
= Creating Data Science Project

In this learning exercise, we will configure a Jupyter notebook server using a specified image within a Data Science project, customizing it to meet your specific requirements. In the Developer Sandbox environment, a Data Science project is created for your convenience. Please navigate to and open this project to set up a Workbench.

.Prerequisites

* An OpenShift cluster


.Procedure

. Click the *Red Hat OpenShift AI* from the  nines menu on the OpenShift Console.

. Click *Log in with OpenShift*

. Click on the *Data Science Projects* tab.

. Click Create project

. Steps about creating a project

. Click on *Create a workbench*. Now you are ready to move to the next step to define the workbench.

.. Give the *workbench* a name.

.. Select the Notebook image from the *image selection dropdown* as *Standard Data Science*.

.. Select the Container size to *small* under *Deployment size*.

.. Scroll down and in the *Cluster storage* section, create new persistent storage and give it a name.

.. Click the *Create workbench* button at the bottom of the page.

After successful implementation, the status of the workbench turns to "Running," similar to Figure 10 below.

.. Click on the *Open↗* button, located beside the status.

.. Authorize the access with the OpenShift cluster by clicking on the *Allow selected permissions*. After granting permissions with OpenShift, you will be directed to the Jupyter Notebook page. 

The Jupyter Notebook provides functionality to fetch or clone existing GitHub repositories, similar to any other standard IDE. Therefore, in this lesson, we will clone an existing simple AI/ML code into the notebook using the following instructions. 

. From the top, click on the *Git clone*  icon.

. Enter the URL of the GitHub repository in the *Git Repository URL* field: 
+
[source,text]
----
https://github.com/redhat-developer-demos/openshift-ai.git
----

. After fetching the github repository, the project will appear in the directory  section on the left side of the notebook.

. Checkout in the "/openshift-ai/first-app/" directory.

. Open the "openshift-ai-test.ipynb" file.
+
[source,terminal]
----
$ git remote add -f upstream git@github.com:validatedpatterns-sandbox/openshift-ai.git 
----

. Verify the setup of your remote repositories by running the following command:
+
[source,terminal]
----
$ git remote -v
----
+
.Example output
+
[source,terminal]
----
origin	git@github.com:<your-username>/openshift-ai.git (fetch)
origin	git@github.com:<your-username>/openshift-ai.git (push)
upstream	git@github.com:validatedpatterns-sandbox/openshift-ai.git (fetch)
upstream	git@github.com:validatedpatterns-sandbox/openshift-ai.git (push)
----

. Create a local copy of the secret values file that can safely include credentials. Run the following commands:
+
[source,terminal]
----
$ cp values-secret.yaml.template ~/values-secret-openshift-ai.yaml
----
+
[NOTE]
====
Putting the `values-secret.yaml` in your home directory ensures that it does not get pushed to your git repository. It is based on the `values-secrets.yaml.template` file provided by the pattern in the top level directory. When you create your own patterns you will add your secrets to this file and save.
====

. Create a new feature branch, for example `my-branch` from the `rhoai` branch for your content:
+
[source,terminal]
----
$ git checkout -b my-branch rhoai
----

. Create a local branch and push it to origin to gain the flexibility needed to customize the OpenShift AI pattern by running the following command:
+
[source,terminal]
----
$ git push origin my-branch
----

You can proceed to install the OpenShift AI pattern by using the web console or from command line by using the script `./pattern.sh` script. 

To install the OpenShift AI pattern by using the web console you must first install the Validated Patterns Operator. The Validated Patterns Operator installs and manages Validated Patterns. 

//Include Procedure module here
[id="installing-validated-patterns-operator_{context}"]
== Installing the {validated-patterns-op} using the web console

.Prerequisites
* Access to an {ocp} cluster by using an account with `cluster-admin` permissions.

.Procedure

. Navigate in the {hybrid-console-first} to the *Operators* → *OperatorHub* page.

. Scroll or type a keyword into the *Filter by keyword* box to find the Operator you want. For example, type `validated patterns` to find the {validated-patterns-op}.

. Select the Operator to display additional information.
+
[NOTE]
====
Choosing a Community Operator warns that Red Hat does not certify Community Operators; you must acknowledge the warning before continuing.
====

. Read the information about the Operator and click *Install*.

. On the *Install Operator* page:

.. Select an *Update channel* (if more than one is available).

.. Select a *Version* (if more than one is available).

.. Select an *Installation mode*:
+
The only supported mode for this Operator is *All namespaces on the cluster (default)*. This installs the Operator in the default `openshift-operators` namespace to watch and be made available to all namespaces in the cluster. This option is not always available.

.. Select *Automatic* or *Manual* approval strategy.

. Click *Install* to make the Operator available to the default `openshift-operators` namespace on this {ocp} cluster.

.Verification
To confirm that the installation is successful:

. Navigate to the *Operators* → *Installed Operators* page.

. Check that the Operator is installed in the selected namespace and its status is `Succeeded`.

//Include Procedure module here
[id="create-pattern-instance_{context}"]
== Creating the OpenShift AI instance

.Prerequisites
The {validated-patterns-op} is successfully installed in the relevant namespace.

.Procedure

. Navigate to the *Operators* → *Installed Operators* page.

. Click the installed *{validated-patterns-op}*.

. Under the *Details* tab, in the *Provided APIs* section, in the
*Pattern* box, click *Create instance* that displays the *Create Pattern* page.

. On the *Create Pattern* page, select *Form view* and enter information in the following fields:

** *Name* - A name for the pattern deployment that is used in the projects that you created.
** *Labels* - Apply any other labels you might need for deploying this pattern.
** *Cluster Group Name* - Select a cluster group name to identify the type of cluster where this pattern is being deployed. For example, if you are deploying the {ie-pattern}, the cluster group name is `datacenter`. If you are deploying the {mcg-pattern}, the cluster group name is `hub`.
+
To know the cluster group name for the patterns that you want to deploy, check the relevant pattern-specific requirements.
. Expand the *Git Config* section to reveal the options and enter the required information.
. Leave *In Cluster Git Server* unchanged. 
.. Change the *Target Repo* URL to your forked repository URL. For example, change `https://github.com/validatedpatterns/<pattern_name>` to `https://github.com/<your-git-username>/<pattern-name>`
.. Optional: You might need to change the *Target Revision* field. The default value is `HEAD`. However, you can also provide a value for a branch, tag, or commit that you want to deploy. For example, `v2.1`, `main`, or a branch that you created, `my-branch`.
. Click *Create*.
+
[NOTE]
====
A pop-up error with the message "Oh no! Something went wrong." might appear during the process. This error can be safely disregarded as it does not impact the installation of the OpenShift AI pattern. Use the Hub ArgoCD UI, accessible through the nines menu, to check the status of ArgoCD instances, which will display states such as progressing, healthy, and so on, for each managed application. The Cluster ArgoCD provides detailed status on each application, as defined in the clustergroup values file.
====

The *{rh-gitops} Operator* displays in list of *Installed Operators*. The *{rh-gitops} Operator* installs the remaining assets and artifacts for this pattern. To view the installation of these assets and artifacts, such as *{rh-rhacm-first}*, ensure that you switch to *Project:All Projects*.

Wait some time for everything to deploy. You can track the progress through the `Hub ArgoCD` UI from the nines menu. The `config-demo` project  appears stuck in a `Degraded` state. This is the expected behavior when installing using the OpenShift Container Platform console.

* To resolve this you need to run the following to load the secrets into the vault:
+
[source,terminal]
----
$ ./pattern.sh make load-secrets
----
+
[NOTE]
====
You must have created a local copy of the secret values file by running the following command:

[source,terminal]
----
$ cp values-secret.yaml.template ~/values-secret-openshift-ai.yaml
----
====

The deployment will not take long but it should deploy successfully.

Alternatively you can deploy the OpenShift AI pattern by using the command line script `pattern.sh`. 

[id="deploying-cluster-using-patternsh-file"]
== Deploying the cluster by using the pattern.sh script

To deploy the cluster by using the `pattern.sh` script, complete the following steps:

. Navigate to the root directory of the cloned repository by running the following command:
+
[source,terminal]
----
$ cd /path/to/your/repository
----

. Log in to your cluster by running the following this procedure:

.. Obtain an API token by visiting https://oauth-openshift.apps.<your-cluster>.<domain>/oauth/token/request

.. Log in with this retrieved token by running the following command:
+
[source,terminal]
----
$ oc login --token=<retrieved-token> --server=https://api.<your-cluster>.<domain>:6443
----

. Alternatively log in by running the following command: 
+
[source,terminal]
----
$ export KUBECONFIG=~/<path_to_kubeconfig>
----

. Deploy the pattern to your cluster by running the following command:
+
[source,terminal]
----
$ ./pattern.sh make install
----

. Verify that the Operators have been installed.
 .. To verify, in the OpenShift Container Platform web console, navigate to *Operators → Installed Operators* page.
 .. Check that *{rh-gitops} Operator* is installed in the `openshift-operators` namespace and its status is `Succeeded`.
. Verify that all applications are synchronized. Under *Networking \-> Routes* select the *Location URL* associated with the *hub-gitops-server* . All application are report status as `Synched`. 
+
image::rhoai/rhods-sync-success.png[ArgoCD Applications,link="/images/rhoai/rhods-sync-success.png"]

As part of installing by using the script `pattern.sh` pattern, HashiCorp Vault is installed. Running `./pattern.sh make install` also calls the `load-secrets` makefile target. This `load-secrets` target looks for a YAML file describing the secrets to be loaded into vault and in case it cannot find one it will use the `values-secret.yaml.template` file in the git repository to try to generate random secrets.

For more information, see section on https://validatedpatterns.io/secrets/vault/[Vault].

[id="verify-rhoai-dashboards"]
== Verify installation by checking the OpenShift AI Dashboard

. Access the OpenShift AI dashboard from nines menu on the OpenShift Console and select the link for **Red Hat OpenShift AI**. 
+
image:rhoai/rhods-application_menu.png[Application ShortCut,link="/images/rhoai/rhods-application_menu.png"]

. Log in to the dashboard using your OpenShift credentials. You will find an environment that is ready for further configuration. This pattern provides the fundamental platform pieces to support MLOps workflows. The installation of OpenShift Pipelines enables the immediate use of pipelines if that is the desired approach for deployment.
+
image:rhoai/rhods-ai_dashboard.png[OpenShift AI Dashboard,link="/images/rhoai/hods-ai_dashboard.png"]